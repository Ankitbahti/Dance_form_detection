{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from shutil import copyfile\n",
    "import shutil\n",
    "import numpy as np \n",
    "# linear algebra\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mohiniyattam     50\n",
       "odissi           49\n",
       "kathakali        47\n",
       "bharatanatyam    47\n",
       "kuchipudi        46\n",
       "sattriya         45\n",
       "kathak           44\n",
       "manipuri         36\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv=pd.read_csv(\"train_dance.csv\")\n",
    "train_csv['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X=train_csv['Image']\n",
    "y=train_csv['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.mkdir('final_train_dir')\n",
    "for i in train_csv['target'].unique():\n",
    "    os.mkdir('final_train_dir/'+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_csv['target'].unique():\n",
    "    for j in X[y==i]:\n",
    "        copyfile('Downloads/dance/train/'+j, 'final_train_dir/'+i+'/'+j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bharatanatyam',\n",
       " 'kathak',\n",
       " 'kathakali',\n",
       " 'kuchipudi',\n",
       " 'manipuri',\n",
       " 'mohiniyattam',\n",
       " 'odissi',\n",
       " 'sattriya']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('final_train_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Flatten,Dense,Dropout\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_learning_rate = ReduceLROnPlateau(monitor='loss',\n",
    "                                        factor=0.1,\n",
    "                                        patience=2,\n",
    "                                        cooldown=2,\n",
    "                                        min_lr=0.00001,\n",
    "                                        verbose=1)\n",
    "\n",
    "callbacks = [reduce_learning_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vggmodel =VGG16(weights='imagenet', include_top=False, input_shape = (224, 224, 3),pooling='max')\n",
    "\n",
    "vggmodel.trainable = False\n",
    "model = Sequential([\n",
    "  vggmodel, \n",
    "  Dense(1024, activation='relu'),\n",
    "  Dropout(0.15),\n",
    "  Dense(256, activation='relu'),\n",
    "  Dropout(0.15),\n",
    "  Dense(8, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile( optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 364 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagenerator = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        featurewise_center=False,  \n",
    "        samplewise_center=False,  \n",
    "        featurewise_std_normalization=False,  \n",
    "        samplewise_std_normalization=False,  \n",
    "        rotation_range=40,  \n",
    "        zoom_range = 0.20,  \n",
    "        width_shift_range=0.10,  \n",
    "        height_shift_range=0.10,  \n",
    "        horizontal_flip=True,  \n",
    "        vertical_flip=False) \n",
    "\n",
    "image_size=224\n",
    "train_generator=train_datagenerator.flow_from_directory(\n",
    "        r\"final_train_dir\",\n",
    "        target_size=(image_size,image_size),\n",
    "#        batch_size=128,\n",
    "        class_mode='categorical'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-24-a69e6c891613>:5: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 12 steps\n",
      "Epoch 1/40\n",
      "12/12 [==============================] - 77s 6s/step - loss: 2.4806 - accuracy: 0.1346\n",
      "Epoch 2/40\n",
      "12/12 [==============================] - 82s 7s/step - loss: 1.8291 - accuracy: 0.3269\n",
      "Epoch 3/40\n",
      "12/12 [==============================] - 88s 7s/step - loss: 1.5958 - accuracy: 0.4038\n",
      "Epoch 4/40\n",
      "12/12 [==============================] - 90s 7s/step - loss: 1.4579 - accuracy: 0.4478\n",
      "Epoch 5/40\n",
      "12/12 [==============================] - 86s 7s/step - loss: 1.2387 - accuracy: 0.5549\n",
      "Epoch 6/40\n",
      "12/12 [==============================] - 86s 7s/step - loss: 1.1558 - accuracy: 0.5907\n",
      "Epoch 7/40\n",
      "12/12 [==============================] - 91s 8s/step - loss: 1.0830 - accuracy: 0.6566\n",
      "Epoch 8/40\n",
      "12/12 [==============================] - 90s 8s/step - loss: 1.0570 - accuracy: 0.6181\n",
      "Epoch 9/40\n",
      "12/12 [==============================] - 96s 8s/step - loss: 1.0311 - accuracy: 0.6374\n",
      "Epoch 10/40\n",
      "12/12 [==============================] - 93s 8s/step - loss: 1.0216 - accuracy: 0.6319\n",
      "Epoch 11/40\n",
      "12/12 [==============================] - 97s 8s/step - loss: 0.9050 - accuracy: 0.6566\n",
      "Epoch 12/40\n",
      "12/12 [==============================] - 95s 8s/step - loss: 0.7952 - accuracy: 0.7253\n",
      "Epoch 13/40\n",
      "12/12 [==============================] - 89s 7s/step - loss: 0.8326 - accuracy: 0.6841\n",
      "Epoch 14/40\n",
      "12/12 [==============================] - 91s 8s/step - loss: 0.7066 - accuracy: 0.7527\n",
      "Epoch 15/40\n",
      "12/12 [==============================] - 93s 8s/step - loss: 0.6551 - accuracy: 0.7445\n",
      "Epoch 16/40\n",
      "12/12 [==============================] - 91s 8s/step - loss: 0.6204 - accuracy: 0.7747\n",
      "Epoch 17/40\n",
      "12/12 [==============================] - 91s 8s/step - loss: 0.6360 - accuracy: 0.7665\n",
      "Epoch 18/40\n",
      "11/12 [==========================>...] - ETA: 7s - loss: 0.6370 - accuracy: 0.7560 \n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "12/12 [==============================] - 91s 8s/step - loss: 0.6576 - accuracy: 0.7500\n",
      "Epoch 19/40\n",
      "12/12 [==============================] - 91s 8s/step - loss: 0.5540 - accuracy: 0.8187\n",
      "Epoch 20/40\n",
      "12/12 [==============================] - 92s 8s/step - loss: 0.5299 - accuracy: 0.8022\n",
      "Epoch 21/40\n",
      "12/12 [==============================] - 91s 8s/step - loss: 0.4799 - accuracy: 0.8407\n",
      "Epoch 22/40\n",
      "12/12 [==============================] - 92s 8s/step - loss: 0.4646 - accuracy: 0.8626\n",
      "Epoch 23/40\n",
      "12/12 [==============================] - 92s 8s/step - loss: 0.4694 - accuracy: 0.8516\n",
      "Epoch 24/40\n",
      "12/12 [==============================] - 90s 7s/step - loss: 0.4263 - accuracy: 0.8599\n",
      "Epoch 25/40\n",
      "12/12 [==============================] - 92s 8s/step - loss: 0.4227 - accuracy: 0.8681\n",
      "Epoch 26/40\n",
      "12/12 [==============================] - 92s 8s/step - loss: 0.4519 - accuracy: 0.8516\n",
      "Epoch 27/40\n",
      "11/12 [==========================>...] - ETA: 7s - loss: 0.4580 - accuracy: 0.8373 \n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "12/12 [==============================] - 92s 8s/step - loss: 0.4641 - accuracy: 0.8379\n",
      "Epoch 28/40\n",
      "12/12 [==============================] - 90s 8s/step - loss: 0.3860 - accuracy: 0.8681\n",
      "Epoch 29/40\n",
      "12/12 [==============================] - 91s 8s/step - loss: 0.4100 - accuracy: 0.8516\n",
      "Epoch 30/40\n",
      "11/12 [==========================>...] - ETA: 7s - loss: 0.4850 - accuracy: 0.8554 \n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "12/12 [==============================] - 86s 7s/step - loss: 0.4732 - accuracy: 0.8599\n",
      "Epoch 31/40\n",
      "12/12 [==============================] - 91s 8s/step - loss: 0.3968 - accuracy: 0.8709\n",
      "Epoch 32/40\n",
      "12/12 [==============================] - 94s 8s/step - loss: 0.4713 - accuracy: 0.8352\n",
      "Epoch 33/40\n",
      "12/12 [==============================] - 98s 8s/step - loss: 0.4524 - accuracy: 0.8407\n",
      "Epoch 34/40\n",
      "12/12 [==============================] - 93s 8s/step - loss: 0.3917 - accuracy: 0.8874\n",
      "Epoch 35/40\n",
      "12/12 [==============================] - 93s 8s/step - loss: 0.4057 - accuracy: 0.8489\n",
      "Epoch 36/40\n",
      "12/12 [==============================] - 92s 8s/step - loss: 0.3867 - accuracy: 0.8709\n",
      "Epoch 37/40\n",
      "12/12 [==============================] - 93s 8s/step - loss: 0.3916 - accuracy: 0.8626\n",
      "Epoch 38/40\n",
      "12/12 [==============================] - 91s 8s/step - loss: 0.4320 - accuracy: 0.8599\n",
      "Epoch 39/40\n",
      "12/12 [==============================] - 91s 8s/step - loss: 0.3859 - accuracy: 0.8874\n",
      "Epoch 40/40\n",
      "12/12 [==============================] - 94s 8s/step - loss: 0.3909 - accuracy: 0.8654\n"
     ]
    }
   ],
   "source": [
    "history =model.fit_generator(\n",
    "    train_generator,\n",
    "    verbose=1,\n",
    "    epochs=40,\n",
    "   callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test/images'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutil.copytree('Downloads/dance/test', 'test/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 156 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "test_generator=test_datagen.flow_from_directory(\n",
    "        r'test',\n",
    "        target_size=(image_size,image_size),\n",
    "#       color_mode=\"rgb\",\n",
    "        batch_size=32,\n",
    "        class_mode=None,\n",
    "        shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-30-aca49b431b9d>:1: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "5/5 [==============================] - 39s 8s/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred=model.predict_generator(test_generator,verbose=1)\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "\n",
    "labels = (train_generator.class_indices)\n",
    "\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results[\"Filename\"]=results[\"Filename\"].apply(lambda x:x[7:])\n",
    "\n",
    "test_csv=pd.read_csv(\"test.csv\")\n",
    "\n",
    "results.set_index([\"Filename\"],inplace=True)\n",
    "test_csv.set_index([\"Image\"],inplace=True)\n",
    "\n",
    "output=test_csv.merge(results,left_index=True,right_index=True)\n",
    "output.index.name='Image'\n",
    "output.rename(columns={'Predictions':'target'},inplace=True)\n",
    "output.to_csv('submission.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
